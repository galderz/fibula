# Fibula

Fibula allows you to run JMH benchmarks as GraalVM native executables.

# Pre-requisites

Build JMH [`1.37-patches` branch](https://github.com/galderz/jmh/tree/1.37-patches) locally to include the following patches:

* Install `jmh-core-it` tests jar locally.
This enables JMH integration tests to be run with Fibula.
* Fix for [`perf stat` command not constructed right for event selection](https://bugs.openjdk.org/browse/CODETOOLS-7903739) bug.
* Fix for [Perf event validation not working with skid options](https://bugs.openjdk.org/browse/CODETOOLS-7903740) bug.

```shell
git clone https://github.com/galderz/jmh && cd jmh
git checkout 1.37-patches
mvn install -DskipTests
```

Build Fibula with JDK 21 or newer:

```shell
mvn install -DskipTests
```

## Getting Started

To run the first JMH benchmark using Fibula,
checkout the
[fibula-show](https://github.com/galderz/fibula-show) repository,
and navigate to the Fibula sample project:

```shell
git clone https://github.com/galderz/fibula-show
cd fibula-show/2406-team/fibula
```

Set the `JAVA_HOME` to GraalVM or Mandrel for JDK 21 or higher,
and build the benchmark:

```shell
mvn package -Pnative
```

Run the benchmark:
```shell
java -jar target/benchmarks.jar MyFirst
```

## Decompiling

Fibula generates bytecode to wrap benchmarks around infrastructure required to measure performance.
This bytecode can optionally be decompiled for closer inspection.
To do that, build the Fibula benchmark with `quarkus.package.jar.decompiler.enabled`.
For example:

```shell
mvn package -Pnative -Dquarkus.package.jar.decompiler.enabled
```

The decompiled output can be located at the `target/decompiled` folder.

## Logging

TODO...

## Profiling

`perf` and `perfnorm` can be used just like with JMH.

JMH `perfasm` profiler is not yet fully supported,
but equivalent functionality can be obtained with the `DwarfPerfAsmProfiler`.
This custom profiler extends the `perf record` arguments to configure `dwarf` callgraph. 

To use this profiler,
the benchmark needs to be built with DWARF debug info.
TODO ...

## Blackholes

TODO ...

Explain if needed to adjust packages/modules for it work with GraalVM 24+

## JMH Features Checklist

These are the JMH features that Fibula currently supports:

- [x] Throughput and average benchmark modes.
- [x] State objects with `Benchmark` and `Thread` scopes.
- [x] Implicit blackhole support for returned values.
- [x] Explicit `Blackhole` benchmark parameters.
- [x] Output time unit definitions via `@OutputTimeUnit` annotation.
- [x] `@Setup` and `@TearDown` annotations.
- [x] `perf` and `perfnorm` profilers.

Some JMH features are partially supported:

* Functionality similar to `perfasm` can be obtained for GraalVM native images
  by running with the ``,
  skipping ASM generation and saving `perf record` binary file.
  Then `perf annotate` can present information  

## JMH Wishlist

aka "The shopping list for Shipilev".

* Make some generator package/class/method visibility public
, instead of default or private.
TODO add specific examples.

## Architecture

Two Quarkus microservices...etc.
TODO

`fibula-benchmarks` module enables end-user experience akin to JMH,
whereby users expect a single `benchmarks.jar` to execute.
It achieves that by depending solely on the `fibula-bootstrap` module,
which is the module where benchmark coordination begins,
and then making the module an `uber-jar`.
This effectively transforms the `fibula-bootstrap` module,
and all of its dependencies,
into a `benchmarks.jar` uber-jar.

## Makefile Guide

Run individual benchmarks in JVM mode:
```shell script
make run BENCHMARK=JMHSample_01
```
Run individual benchmarks in Native mode:
```shell script
make run-native BENCHMARK=JMHSample_01
```
Running a benchmark with Linux perf stat profiler:
```shell script
make run-native BENCHMARK=JMHSample_01 PROFILER=perf
```
Decompile generated bytecode:
```shell script
make test DECOMPILE=true
```
Debugging benchmark generation for one of the tests:
```shell script
make test MAVEN_DEBUG=process GEN=BenchmarkStateOrderTest
```
Debugging benchmark test execution for one of the tests:
```shell script
make test MAVEN_DEBUG=test TEST=FailureModesTest
```
Running a benchmark sample in Native mode with perf stat profiler:
```shell script
make run-native BENCHMARK=JMHSample_01 PROF=perf
```
Running a benchmark sample in Native mode with perf stat or perf norm profiler with only branches and instructions
(needs https://github.com/galderz/jmh/commit/4000d778664e5a138fef8b8b79d3a823fa843527 to avoid multiplexing):
```shell script
make run-native BENCHMARK=JMHSample_01 PROF=perf:events=branches,instructions
make run-native BENCHMARK=JMHSample_01 PROF=perfnorm:events=branches,instructions
```
Running a benchmark sample in JVM mode with perf stat profiler:
```shell script
make run BENCHMARK=JMHSample_01 PROF=perf
```
Running a benchmark sample in Native mode with perfasm and saving the perf bin data:
```shell script
make run-native BENCHMARK=JMHSample_01 PROF=perfasm:skipAsm=true\\\;savePerfBin=true
```
Running a benchmark sample in Native mode with perfasm that uses DWARF call graph and saving the perf bin data
(needs https://github.com/galderz/jmh/commit/e623b6a93263fa24d5ec11076b59b3ea3b8dd0fc to enable modifiers):
```shell script
make run-native BENCHMARK=JMHSample_01 PROF=org.mendrugo.fibula.bootstrap.DwarfPerfAsmProfiler:events=cycles:P\\\;skipAsm=true\\\;savePerfBin=true DEBUG_INFO=true MEASURE_TIME=1 WARMUP_TIME=1
```

## TODO

- [ ] Print executing/results as TRACE and make results/params presented not in base64 format
- [ ] Separate building bootstrap+runner from running it (to avoid repeat build if source not changed)
- [ ] Avoid the BenchmarkList file and instead emit a build item and use the recorder
- [ ] Support running jvm mode with native image agent
      Doing this will require fixing the forking to avoid errors related to writing to same native image config file
      Once that is fixed, maybe default to running with only 1 fork and 1 warmup and 1 measurement fork, because that should be enough
- [ ] Add a record equals/hashCode benchmark
      Some potential examples:
      https://github.com/openjdk/jdk/blob/master/test/micro/org/openjdk/bench/java/io/RecordDeserialization.java
- [ ] See how record equals/hashCode benchmark behaves with different GraalVM versions
- [ ] Add profiler integration
      `perf annotate` is one option
      , another is to use `perf stat` along with `perf norm`
- [ ] Narrow down native issue with commons match dependency